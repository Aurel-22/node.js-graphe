# Architecture Base de DonnÃ©es â€” Graph Visualizer

## Table des matiÃ¨res

1. [Vue d'ensemble](#1-vue-densemble)
2. [Comparatif des trois moteurs](#2-comparatif-des-trois-moteurs)
3. [Analyse dÃ©taillÃ©e par moteur](#3-analyse-dÃ©taillÃ©e-par-moteur)
4. [Le problÃ¨me des CTE rÃ©cursives MSSQL](#4-le-problÃ¨me-des-cte-rÃ©cursives-mssql)
5. [Optimisations de l'affichage](#5-optimisations-de-laffichage)
6. [ImplÃ©mentation du temps rÃ©el](#6-implÃ©mentation-du-temps-rÃ©el)
7. [Futures implÃ©mentations](#7-futures-implÃ©mentations)

---

## 1. Vue d'ensemble

Le projet utilise un **Strategy Pattern** : tous les moteurs implÃ©mentent l'interface `GraphDatabaseService` (15 mÃ©thodes), ce qui permet de les interchanger via un simple paramÃ¨tre `?engine=neo4j|memgraph|mssql` dans chaque requÃªte HTTP.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend    â”‚â”€â”€RESTâ”€â”€â–¶â”‚  Express (resolveEngine)    â”‚
â”‚  React/Vite  â”‚         â”‚  ?engine=xxx â†’ dbService    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                                  â”‚       â”‚        â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â” â”Œâ”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”´â”€â”€â”€â”€â”€â”€â”
                           â”‚ Neo4j   â”‚ â”‚Memgraphâ”‚ â”‚ MSSQL  â”‚
                           â”‚ Bolt 5  â”‚ â”‚ Bolt 4 â”‚ â”‚ TDS    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DonnÃ©es stockÃ©es** : chaque moteur gÃ¨re 3 entitÃ©s :
| EntitÃ© | Neo4j/Memgraph | MSSQL |
|--------|----------------|-------|
| MÃ©tadonnÃ©es graphe | Label `:Graph` | Table `graphs` |
| NÅ“uds | Label `:GraphNode` | Table `graph_nodes` |
| ArÃªtes | Relation `:CONNECTED_TO` | Table `graph_edges` |

---

## 2. Comparatif des trois moteurs

### 2.1 Performances mesurÃ©es (graphes multi-communautÃ©s, ~3 arÃªtes/nÅ“ud)

| OpÃ©ration | Neo4j 5.26 | Memgraph 2.x | MSSQL 2022 |
|-----------|-----------|--------------|------------|
| **CrÃ©ation 1K nÅ“uds** | 1.1 s | 1.9 s | 1.8 s |
| **CrÃ©ation 2K nÅ“uds** | 1.3 s | 6.1 s | 3.3 s |
| **CrÃ©ation 5K nÅ“uds** | 3.3 s | 35.9 s | 8.1 s |
| **CrÃ©ation 10K nÅ“uds** | 6.2 s | 139 s | 16 s |
| **Lecture graphe (cache miss)** | ~20â€“50 ms | ~20â€“50 ms | ~10â€“30 ms |
| **Lecture graphe (cache hit)** | < 1 ms | < 1 ms | < 1 ms |
| **TraversÃ©e voisins (depth=2)** | ~5â€“15 ms | ~5â€“15 ms | ~50â€“300 ms |
| **TraversÃ©e voisins (depth=5)** | ~10â€“40 ms | ~10â€“40 ms | **500 msâ€“10 s** |

### 2.2 SynthÃ¨se comparative

| CritÃ¨re | Neo4j | Memgraph | MSSQL |
|---------|-------|----------|-------|
| **Type** | BD graphe native (disque) | BD graphe native (in-memory) | BD relationnelle |
| **ModÃ¨le de stockage** | Index-free adjacency (disque + cache) | Index-free adjacency (RAM) | Tables + index B-tree |
| **Protocole** | Bolt 5.x | Bolt 4.x | TDS (Tabular Data Stream) |
| **Langage de requÃªte** | Cypher | Cypher (sous-ensemble) | T-SQL + CTE rÃ©cursive |
| **Multi-database** | âœ… Oui | âŒ Non | âœ… Oui |
| **Authentification** | âœ… user/pass | âŒ Aucune par dÃ©faut | âœ… SA/user |
| **TraversÃ©e de graphe** | Native O(1) par saut | Native O(1) par saut | CTE rÃ©cursive O(nÂ·m) |
| **Ã‰criture batch** | UNWIND (500/batch) | UNWIND (500/batch) hÃ©ritÃ© | Multi-value INSERT (500/batch) |
| **Clustering natif** | âœ… (algorithmes intÃ©grÃ©s) | âœ… (MAGE: +130 algos) | âŒ Manuel uniquement |
| **Consommation RAM** | ~500 Mo (Docker) | ~200 Moâ€“2 Go (tout en RAM) | ~1.5 Go (Docker) |
| **Licence** | Community (GPLv3) / Enterprise | BSL â†’ Apache2 | PropriÃ©taire (Developer gratuit) |

---

## 3. Analyse dÃ©taillÃ©e par moteur

### 3.1 Neo4j

**Comment Ã§a fonctionne dans le projet :**
- Le driver `neo4j-driver@5.28.3` communique en Bolt 5.x
- Les requÃªtes `getGraph()` lancent 2 sessions parallÃ¨les via `Promise.all()` (nÅ“uds + arÃªtes)
- Les insertions utilisent `UNWIND $batch` pour envoyer 500 nÅ“uds par requÃªte Cypher
- Cache `NodeCache` avec TTL 5 min, clÃ© : `graph:<database>:<graphId>`
- Index composite `(graph_id, node_id)` sur `:GraphNode`

**Avantages :**
- TraversÃ©e native : chaque nÅ“ud contient un pointeur direct vers ses voisins â†’ O(1) par saut (pas de jointure)
- Langage Cypher expressif pour les patterns complexes (`MATCH path = (a)-[*1..5]->(b)`)
- Multi-database : chaque projet peut avoir sa propre base isolÃ©e
- Ã‰cosystÃ¨me riche : APOC, GDS (Graph Data Science), Neo4j Bloom
- Plan d'exÃ©cution visualisable (`PROFILE / EXPLAIN`)

**InconvÃ©nients :**
- Ã‰criture plus lente que MSSQL pour les insertions massives (transactions ACID strictes)
- Consommation mÃ©moire importante en production (recommandÃ© 4 Go+ heap)
- Version Community limitÃ©e (pas de clustering, pas de Causal Cluster)
- Docker `--network=host` obligatoire dans certains environnements (proxy)
- Driver v6 incompatible (fallback v5.28.3 nÃ©cessaire)

### 3.2 Memgraph

**Comment Ã§a fonctionne dans le projet :**
- HÃ©rite de `Neo4jService` (extends) â†’ mÃªme code Cypher
- Driver `neo4j-driver@4.4.x` aliasÃ© en `neo4j-driver-memgraph` (Bolt 4.x uniquement)
- Pas d'authentification, pas de multi-database
- Toutes les donnÃ©es sont en RAM â†’ lectures ultra-rapides sur des graphes chargÃ©s

**Avantages :**
- Toutes les donnÃ©es en RAM â†’ latence de lecture la plus basse (sub-milliseconde)
- Compatible Cypher â†’ hÃ©ritage direct du code Neo4j (zÃ©ro rÃ©Ã©criture)
- MAGE : 130+ algorithmes (PageRank, Louvain, Betweenness Centrality, communautÃ©sâ€¦)
- Streams Kafka/Pulsar natifs â†’ idÃ©al pour le temps rÃ©el
- LÃ©ger : ~200 Mo Docker de base

**InconvÃ©nients :**
- **Ã‰criture trÃ¨s lente** avec `UNWIND` + `MATCH` pour les arÃªtes : Memgraph effectue un full scan par MATCH dans chaque UNWIND car les **index composites ne sont pas supportÃ©s** en v2.x
  - 10K nÅ“uds : 139 s contre 6 s sur Neo4j (Ã—23 plus lent)
  - C'est le principal goulot sur ce projet
- Pas de multi-database â†’ toutes les donnÃ©es dans un seul namespace
- Persistence dÃ©sactivÃ©e par dÃ©faut (donnÃ©es perdues au redÃ©marrage sauf config WAL)
- Pas de plan `PROFILE` aussi dÃ©taillÃ© que Neo4j
- Bolt 4.x uniquement â†’ ne supporte pas neo4j-driver v5/v6

### 3.3 MSSQL (SQL Server 2022)

**Comment Ã§a fonctionne dans le projet :**
- Driver `mssql@12.2.0` avec connection pooling (`max: 10`, idle timeout 30s)
- ModÃ¨le relationnel : 3 tables (`graphs`, `graph_nodes`, `graph_edges`) avec FK + `ON DELETE CASCADE`
- Insertion batch : multi-value INSERT de 500 lignes par requÃªte (limite SQL Server : 2100 paramÃ¨tres)
- TraversÃ©e via **CTE rÃ©cursive** (`WITH Traverse AS (... UNION ALL ...)`)
- RequÃªtes nÅ“uds + arÃªtes en `Promise.all()` comme Neo4j

**Avantages :**
- SQL standard â†’ toute l'Ã©quipe sait Ã©crire des requÃªtes
- FacilitÃ© de jointure avec d'autres donnÃ©es mÃ©tier (CMDB, ticketing, inventaire)
- Transactions ACID robustes, sauvegardes simples
- Multi-database natif avec `sys.databases`
- Insertion batch plus rapide que Memgraph (16 s pour 10K vs 139 s)
- Outils d'administration matures (SSMS, Azure Data Studio)

**InconvÃ©nients :**
- **Pas de traversÃ©e native** â†’ CTE rÃ©cursive obligatoire (voir section 4)
- Pas de langage graphe â†’ les patterns de traversÃ©e sont verbeux en T-SQL
- Pas d'algorithmes de graphe intÃ©grÃ©s (clustering, PageRank, centralitÃ©)
- Consommation RAM Ã©levÃ©e (~1.5 Go minimum Docker)
- Licence propriÃ©taire (Developer gratuit uniquement pour le dev)

---

## 4. Le problÃ¨me des CTE rÃ©cursives MSSQL

### 4.1 Comment fonctionne la traversÃ©e actuelle

Quand le frontend demande les voisins d'un nÅ“ud (analyse d'impact, exploration), MSSQL utilise une **CTE rÃ©cursive** :

```sql
WITH Traverse AS (
  -- Ancre : le nÅ“ud de dÃ©part
  SELECT node_id, 0 AS lvl
  FROM graph_nodes
  WHERE graph_id = @graphId AND node_id = @nodeId

  UNION ALL

  -- RÃ©cursion : pour chaque nÅ“ud trouvÃ©, chercher ses voisins
  SELECT n.node_id, t.lvl + 1
  FROM Traverse t
  JOIN graph_edges e ON e.source_id = t.node_id
  JOIN graph_nodes n ON n.node_id = e.target_id
  WHERE t.lvl < @maxDepth
)
```

Le code actuel fait **deux CTE** (sortante + entrante) combinÃ©es par `UNION`, puis un second `SELECT` pour rÃ©cupÃ©rer les arÃªtes, le tout dans une seule requÃªte avec `OPTION (MAXRECURSION 200)`.

### 4.2 Pourquoi c'est un problÃ¨me

| Aspect | Neo4j / Memgraph | MSSQL CTE rÃ©cursive |
|--------|------------------|---------------------|
| **ComplexitÃ©** | O(k^d) avec k = degrÃ© moyen, d = profondeur. Chaque saut est un pointer follow : O(1) | O(k^d Ã— n) â€” chaque niveau refait un `JOIN` sur table complÃ¨te |
| **Index** | Index-free adjacency : le nÅ“ud contient la liste de ses relations | INDEX B-tree sur `graph_id` : lookup O(log n) par jointure |
| **Profondeur 2** | ~5â€“15 ms | ~50â€“300 ms |
| **Profondeur 5+** | ~10â€“40 ms | **500 ms Ã  10+ s** â€” croissance exponentielle |
| **DÃ©tection de cycles** | Natif (`shortestPath`, flags visited) | Aucun : MSSQL peut boucler â†’ il faut capper `MAXRECURSION` |
| **MÃ©moire** | Parcours en streaming | CTE matÃ©rialisÃ©e en `tempdb` â†’ pression mÃ©moire |

### 4.3 Impact sur les fonctionnalitÃ©s

**Temps d'affichage :**
Pour `getGraph()` (charger un graphe entier), les 3 moteurs sont comparables (~10â€“50 ms) car c'est un simple `SELECT WHERE graph_id = X` et les rÃ©sultats sont cachÃ©s. Le problÃ¨me apparaÃ®t uniquement lors de la **traversÃ©e dynamique** (`getNodeNeighbors`).

**Analyse d'impact (ImpactAnalysis) :**
L'outil ImpactAnalysis du frontend charge d'abord le graphe entier en mÃ©moire, puis calcule la propagation cÃ´tÃ© client avec `graphology`. La traversÃ©e MSSQL n'est donc pas utilisÃ©e ici â†’ **pas de problÃ¨me direct** pour l'impact. Mais si on voulait faire de l'analyse d'impact cÃ´tÃ© serveur (plus scalable), la CTE rÃ©cursive deviendrait un vrai goulot.

**Clustering :**
MSSQL n'a **aucun algorithme de clustering natif**. Pour dÃ©tecter des communautÃ©s (Louvain, Label Propagation), il faudrait :
- Soit extraire les donnÃ©es et les envoyer Ã  une librairie externe (Python `igraph`, `networkx`)
- Soit dupliquer les donnÃ©es dans Neo4j/Memgraph pour utiliser leurs algorithmes natifs
- Neo4j dispose de GDS (Graph Data Science Library) avec Louvain, PageRank, WCC, etc.
- Memgraph dispose de MAGE avec 130+ algorithmes intÃ©grÃ©s directement en Cypher

### 4.4 Comment optimiser MSSQL si on le conserve

1. **Index couvrant sur les arÃªtes** :
   ```sql
   CREATE INDEX IX_edges_source ON graph_edges (graph_id, source_id) INCLUDE (target_id, label, edge_type);
   CREATE INDEX IX_edges_target ON graph_edges (graph_id, target_id) INCLUDE (source_id, label, edge_type);
   ```

2. **Limiter la profondeur** : capper `depth` Ã  3 maximum en production (actuellement limitÃ© Ã  15 dans le code, mais 5+ est dÃ©jÃ  problÃ©matique).

3. **Table temporaire avec dÃ©doublonnage** : au lieu de laisser la CTE revisiter des nÅ“uds, utiliser une table `#visited` et y insÃ©rer au fur et Ã  mesure.

4. **PrÃ©-calculer les chemins** : pour des patterns d'impact rÃ©currents, stocker les rÃ©sultats de traversÃ©e dans une table de cache.

5. **Graph Tables SQL Server 2017+** : SQL Server supporte `CREATE TABLE AS NODE` / `AS EDGE` + `MATCH (a)-(e)->(b)` â€” syntaxe dÃ©diÃ©e graphe, mais limitÃ©e en fonctionnalitÃ©s.

---

## 5. Optimisations de l'affichage

### 5.1 Optimisations backend dÃ©jÃ  en place

| Optimisation | DÃ©tail |
|---|---|
| **Cache NodeCache** | TTL 5 min, invalidation sur write. Headers `X-Cache: HIT/MISS` |
| **RequÃªtes parallÃ¨les** | `Promise.all()` pour nÅ“uds + arÃªtes (Neo4j, MSSQL) |
| **UNWIND batching** | Insertion par lots de 500 (Neo4j/Memgraph) ou 400â€“500 (MSSQL) |
| **Compression gzip** | Express `compression()` middleware |
| **Headers performance** | `X-Response-Time`, `X-Parallel-Queries`, `X-Engine` |

### 5.2 Optimisations frontend dÃ©jÃ  en place

| Optimisation | DÃ©tail |
|---|---|
| **Rendu adaptatif** | Chaque viewer ajuste taille des nÅ“uds, labels, physique selon le `nodeCount` (seuils : <500, 500â€“2K, 2Kâ€“5K, 5Kâ€“10K, >10K) |
| **FPS Counter** | Canvas sparkline pour monitorer les performances de rendu |
| **7 moteurs de visualisation** | Force-Graph 2D, 3D, Sigma.js, G6, D3, Cytoscape, vis-network â€” chacun avec ses compromis perf/qualitÃ© |
| **Impact Analysis** | Propagation calculÃ©e cÃ´tÃ© client avec `graphology` + ForceAtlas2 |

### 5.3 Pistes d'optimisation supplÃ©mentaires

#### Backend

1. **Pagination des graphes** : au lieu de renvoyer 10K nÅ“uds d'un coup, implÃ©menter un `GET /graphs/:id?limit=500&offset=0` avec chargement incrÃ©mental.

2. **Streaming JSON** : utiliser `res.write()` + `Transfer-Encoding: chunked` pour envoyer les nÅ“uds au fur et Ã  mesure au lieu d'attendre la sÃ©rialisation complÃ¨te.

3. **Compression binaire** : remplacer JSON par **MessagePack** ou **Protocol Buffers** â€” rÃ©duction de ~60 % de la taille des payloads pour les gros graphes.

4. **Redis comme cache** : remplacer `NodeCache` (in-process) par Redis pour partager le cache entre plusieurs instances et survivre aux redÃ©marrages.

5. **Index de voisinage** : stocker pour chaque nÅ“ud sa liste d'adjacence prÃ©-calculÃ©e (JSON array de `node_id` voisins) pour Ã©viter les traversÃ©es dynamiques.

#### Frontend

1. **WebGL obligatoire >5K nÅ“uds** : forcer Sigma.js ou Force-Graph 3D au-delÃ  de 5K nÅ“uds (Canvas 2D est trop lent).

2. **Level-of-Detail (LOD)** : ne rendre les labels et les dÃ©tails que quand le zoom dÃ©passe un seuil. Sigma.js le fait dÃ©jÃ  avec `labelRenderedSizeThreshold`.

3. **Chargement progressif** : charger d'abord les hubs (nÅ“uds avec le plus de connexions), puis les dÃ©tails Ã  la demande.

4. **Web Workers** : dÃ©porter le layout (ForceAtlas2, force simulation) dans un Worker pour ne pas bloquer le thread principal.

5. **Virtualization** : pour les listes de graphes et les panneaux latÃ©raux, utiliser `react-virtualized` pour ne rendre que les Ã©lÃ©ments visibles.

6. **Layout prÃ©-calculÃ©** : au lieu de calculer la physique cÃ´tÃ© client, envoyer les positions `(x, y)` depuis le serveur (calculÃ©es une seule fois et cachÃ©es).

---

## 6. ImplÃ©mentation du temps rÃ©el

### 6.1 Architecture proposÃ©e

Pour ajouter/retirer des nÅ“uds et voir les rÃ©percussions en temps rÃ©el, l'architecture suivante est recommandÃ©e :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend    â”‚â—„â”€â”€WebSocketâ”€â”€â–¶ â”‚  Backend Express â”‚
â”‚  React SPA   â”‚                â”‚  + Socket.IO     â”‚
â”‚  Sigma/Force â”‚                â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚  BD Graphe        â”‚
                                â”‚  (Neo4j/Memgraph) â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Ã‰tapes d'implÃ©mentation

#### Ã‰tape 1 â€” WebSocket avec Socket.IO

```bash
# Backend
npm install socket.io

# Frontend
npm install socket.io-client
```

**Backend** â€” ajouter dans `index.ts` :
```typescript
import { Server } from 'socket.io';
import { createServer } from 'http';

const httpServer = createServer(app);
const io = new Server(httpServer, {
  cors: { origin: '*' }
});

io.on('connection', (socket) => {
  console.log(`Client connected: ${socket.id}`);

  socket.on('join-graph', (graphId: string) => {
    socket.join(`graph:${graphId}`);
  });

  socket.on('disconnect', () => {
    console.log(`Client disconnected: ${socket.id}`);
  });
});

// Exporter io pour l'utiliser dans les routes
export { io };
```

#### Ã‰tape 2 â€” API de mutations temps rÃ©el

CrÃ©er de nouvelles routes REST + Ã©mission WebSocket :

```typescript
// POST /api/graphs/:id/nodes â€” Ajouter un nÅ“ud
router.post('/graphs/:id/nodes', async (req, res) => {
  const { node } = req.body;  // { id, label, node_type, properties }
  await service.addNode(graphId, node, database);

  // Notifier tous les clients qui visualisent ce graphe
  io.to(`graph:${graphId}`).emit('node:added', { graphId, node });
  res.status(201).json(node);
});

// DELETE /api/graphs/:id/nodes/:nodeId â€” Retirer un nÅ“ud
router.delete('/graphs/:id/nodes/:nodeId', async (req, res) => {
  await service.removeNode(graphId, nodeId, database);

  io.to(`graph:${graphId}`).emit('node:removed', { graphId, nodeId });
  res.status(204).send();
});

// POST /api/graphs/:id/incidents â€” CrÃ©er un incident
router.post('/graphs/:id/incidents', async (req, res) => {
  const { nodeId, type, severity } = req.body;

  // Calculer la propagation d'impact
  const impacted = await service.getNodeNeighbors(graphId, nodeId, 3, database);

  io.to(`graph:${graphId}`).emit('incident:created', {
    graphId,
    source: nodeId,
    type,
    severity,
    impactedNodes: impacted.nodes.map(n => n.id),
  });

  res.json({ source: nodeId, impactedCount: impacted.nodes.length });
});
```

#### Ã‰tape 3 â€” Frontend : Ã©couter les Ã©vÃ©nements

```typescript
import { io } from 'socket.io-client';

const socket = io('http://127.0.0.1:8080');

// Rejoindre la room du graphe affichÃ©
useEffect(() => {
  if (selectedGraphId) {
    socket.emit('join-graph', selectedGraphId);

    socket.on('node:added', ({ node }) => {
      setGraphData(prev => ({
        ...prev!,
        nodes: [...prev!.nodes, node],
      }));
    });

    socket.on('node:removed', ({ nodeId }) => {
      setGraphData(prev => ({
        ...prev!,
        nodes: prev!.nodes.filter(n => n.id !== nodeId),
        edges: prev!.edges.filter(e => e.source !== nodeId && e.target !== nodeId),
      }));
    });

    socket.on('incident:created', ({ source, impactedNodes, severity }) => {
      // Mettre en surbrillance les nÅ“uds impactÃ©s
      highlightNodes(impactedNodes, severity);
    });

    return () => {
      socket.off('node:added');
      socket.off('node:removed');
      socket.off('incident:created');
    };
  }
}, [selectedGraphId]);
```

#### Ã‰tape 4 â€” Simulation d'incidents

Ajouter un panneau UI "Incident Simulator" :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”´ Incident Simulator          â”‚
â”‚                                  â”‚
â”‚  NÅ“ud source : [dropdown]        â”‚
â”‚  Type :  â—‹ Panne  â—‹ Surcharge    â”‚
â”‚  SÃ©vÃ©ritÃ© : [1] [2] [3] [4] [5] â”‚
â”‚  Profondeur propagation : [3]    â”‚
â”‚                                  â”‚
â”‚  [ DÃ©clencher l'incident ]       â”‚
â”‚  [ Restaurer le nÅ“ud ]           â”‚
â”‚                                  â”‚
â”‚  NÅ“uds impactÃ©s : 47 / 1000     â”‚
â”‚  Temps de propagation : 12 ms    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.3 Quel moteur pour le temps rÃ©el ?

| CritÃ¨re | Neo4j | Memgraph | MSSQL |
|---------|-------|----------|-------|
| **Ã‰criture unitaire (1 nÅ“ud)** | ~2â€“5 ms | ~1â€“3 ms | ~3â€“8 ms |
| **TraversÃ©e d'impact depth=3** | ~5â€“15 ms | ~5â€“15 ms | ~50â€“300 ms |
| **Streaming natif** | âŒ (Change Data Capture via connector) | âœ… Kafka/Pulsar natif | âŒ (CDC SQL Server) |
| **RecommandÃ© pour temps rÃ©el** | âœ… Bon | âœ…âœ… Excellent | âš ï¸ Acceptable si depth â‰¤ 2 |

**Recommandation** : Memgraph est le meilleur choix pour le temps rÃ©el grÃ¢ce Ã  son stockage tout-en-RAM et ses streams natifs. Neo4j est un bon second choix. MSSQL est utilisable mais la latence de traversÃ©e au-delÃ  de depth=2 dÃ©gradera l'expÃ©rience temps rÃ©el.

---

## 7. Futures implÃ©mentations

### 7.1 Court terme (semaines)

| FonctionnalitÃ© | DÃ©tail | Moteur concernÃ© |
|---|---|---|
| **CRUD nÅ“uds/arÃªtes unitaires** | `addNode()`, `removeNode()`, `addEdge()`, `removeEdge()` dans `GraphDatabaseService` | Tous |
| **WebSocket Socket.IO** | Notifications temps rÃ©el de mutations | Backend |
| **Incident Simulator** | Panneau UI pour dÃ©clencher/restaurer des pannes et voir la propagation | Frontend |
| **Index couvrants MSSQL** | `IX_edges_source`, `IX_edges_target` avec `INCLUDE` | MSSQL |
| **Pagination de graphes** | `?limit=500&offset=0` pour les gros graphes | Tous |

### 7.2 Moyen terme (mois)

| FonctionnalitÃ© | DÃ©tail |
|---|---|
| **Algorithmes de graphe** | IntÃ©grer GDS (Neo4j) ou MAGE (Memgraph) pour PageRank, Louvain, Shortest Path, Betweenness Centrality |
| **Layout serveur** | Calculer les positions `(x, y)` cÃ´tÃ© serveur avec ForceAtlas2, les cacher, et les envoyer au frontend (Ã©vite le lag initial) |
| **Diff de graphes** | Comparer deux versions d'un graphe et montrer les nÅ“uds ajoutÃ©s/supprimÃ©s/modifiÃ©s |
| **RBAC** | RÃ´les et permissions par graphe/database (lecture seule, Ã©dition, admin) |
| **Import/Export** | Supporter GEXF, GraphML, CSV pour l'import/export de graphes |
| **Historique des mutations** | Event sourcing : stocker chaque mutation en append-only pour replay et undo |

### 7.3 Long terme (trimestre+)

| FonctionnalitÃ© | DÃ©tail |
|---|---|
| **Multi-tenant** | Isoler les donnÃ©es par organisation (un namespace / database par tenant) |
| **Dashboard monitoring** | Graphiques Grafana/Prometheus des mÃ©triques : latence par engine, cache hit ratio, taille des graphes |
| **GraphQL API** | Remplacer ou complÃ©ter REST par GraphQL pour des requÃªtes plus flexibles cÃ´tÃ© frontend |
| **IA / LLM** | RequÃªtes en langage naturel ("montre-moi les services impactÃ©s par le serveur X") traduites en Cypher |
| **Benchmark automatisÃ©** | CI pipeline qui exÃ©cute les mÃªmes opÃ©rations sur les 3 engines et gÃ©nÃ¨re un rapport comparatif |
| **3D immersif** | Visualisation VR/AR des graphes avec WebXR + Three.js |

---

## Annexe â€” RÃ©sumÃ© des choix techniques

| DÃ©cision | Choix actuel | Justification |
|---|---|---|
| Cache | NodeCache in-process (5 min TTL) | Simple, zÃ©ro dÃ©pendance externe, suffisant en mono-instance |
| Batch insert Neo4j | UNWIND 500/batch | Optimal entre latence rÃ©seau et taille de transaction |
| Batch insert MSSQL | Multi-value INSERT 500 lignes | Limite SQL Server de 2100 paramÃ¨tres â†’ max 500 lignes Ã— 4 cols |
| TraversÃ©e MSSQL | Double CTE rÃ©cursive (out + in) | Seule option native T-SQL, cappÃ©e Ã  depth=15, MAXRECURSION=200 |
| Docker networking | `--network=host` pour les 3 | Proxy rÃ©seau de l'environnement bloque le bridge Docker |
| Memgraph driver | neo4j-driver@4.4.x aliasÃ© | Memgraph 2.x rejette Bolt 5.x, impose Bolt 4.x |
| Frontend viewers | 7 moteurs + ImpactAnalysis | Chaque viewer a des compromis perf/qualitÃ© diffÃ©rents selon la taille du graphe |
